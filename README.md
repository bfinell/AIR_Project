# GPTellMeTheAnswer: Comparing LLM answers against document retrieval

## Final project for advanced information retrieval 

Abstract: Lately it has become more and more common to discard of the old ways of finding your answers through Google or other such media, instead one simply pays a visit to one's favourite Large Language Model (e.g. ChatGPT, Bard etc.) of choice and queries it regarding the matter about which one wishes to know more. A shining example of this can be seen in the drastic drop in StackOverflow visitors after the release of ChatGPT.

The main focus of the project will be to first query a/several large language models with a query and store the answers. The documents and answers will then both be processed and ranked for relevance against the query. What this project endeavours to find out is how the answers from a large language model perform in a relevance ranking against a dataset of documents.

In this project we are using the [Wikipedia Summary Dataset](https://thijs.ai/Wikipedia-Summary-Dataset/)
The dataset contains the extracted summaries of Wikipedia articles.
A summary or introduction of an article is everything starting from the page title up to the content outline.


The models used for this project are:
- Microsoft/phi2
- TheBloke/vicuna

### contributors
  - Benjamin Finell
  - Jakob Stanta
  - Joar Sabel
    
